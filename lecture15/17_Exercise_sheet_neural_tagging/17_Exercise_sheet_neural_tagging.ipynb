{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sB9EwaZbbKMN"
   },
   "source": [
    "# Exercise Lecture \"15: Neural Sequence Tagging\"\n",
    "\n",
    "In this assignement, we learn a model which can detect noun phrases referring to visual entities given the Flicker30k entities corpus as training data.\n",
    "\n",
    "In this corpus, each word is labelled with either (B) if that word starts an NP, (I) if it occurs within an NP and (O) otherwise. There is one word and one label per line. Sentences are separated by blank lines. \n",
    "\n",
    "Data file:  f30kE-captions-bio.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecqfYZ4kbKMh"
   },
   "source": [
    "#### Exercise 1 - Creating a list of lists of tokens (one list per sentence) and the corresponding lists of labels\n",
    "\n",
    "* From the input file, create two lists called \"texts\" and \"labels\"\n",
    "* \"text\" is a list of lists, each list containing the tokens of a sentence\n",
    "* \"labels\" contains the list of lists of labels for each sentence in \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"f30kE-captions-bio/f30kE-captions-bio.txt\"\n",
    "data = open(data_dir, \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\experiments\\cours nlp\\data science\\lecture15\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5501, 5501)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "labels = []\n",
    "sent_token = []\n",
    "sent_lab = []\n",
    "for line in data.split('\\n'):\n",
    "    if line:\n",
    "        token, label = line[:-2], line[-1]\n",
    "        sent_token.append(token)\n",
    "        sent_lab.append(label)\n",
    "    else:\n",
    "        assert len(sent_token) == len(sent_lab)\n",
    "        assert len(set(sent_lab)) <= 3\n",
    "        text.append(sent_token) \n",
    "        labels.append(sent_lab)\n",
    "        sent_token, sent_lab = [], []\n",
    "assert len(text) == len(labels)\n",
    "len(text), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuckS_TsbKMy"
   },
   "source": [
    "#### Exercise 2 -  Mapping labels to integers and sequence of labels to sequence of integers\n",
    "\n",
    "* Create a dictionary label2int which maps each label to a distinct integer\n",
    "* Apply this dictionary to the list of labels extracted in the previous exercise \n",
    "\n",
    "**Hint:** We did this in the preceding lab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "label2int = defaultdict(lambda: len(label2int))\n",
    "label2int['<eos>'] = 0\n",
    "for labl in ['I', 'O', 'B']:\n",
    "    [label2int[label] for label in ['I', 'O', 'B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_token = set([l.lower() for t in text for l in t])\n",
    "token2int = defaultdict(lambda: len(token2int))\n",
    "token2int['<eos>'] = 0\n",
    "for l in text:\n",
    "    [token2int[token.lower()] for token in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_int = []\n",
    "for sent in text:\n",
    "    to_add = 16-len(sent)\n",
    "    sent += ['<eos>']*to_add\n",
    "    text_int.append(sent)\n",
    "text_int = [[token2int[token.lower()] for token in l] for l in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_int=[]\n",
    "for label in labels:\n",
    "    to_add = 16-len(label)\n",
    "    label += ['<eos>']*to_add\n",
    "    label_int.append(label)\n",
    "label_int = [[label2int[token] for token in l] for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmX8f6yUbKM5"
   },
   "source": [
    "#### Exercise 3 - Convert the tokens to integers\n",
    "\n",
    "* Similarly define a token2int dictionary mapping each token in your corpus to an integer and use this dictionary to convert the texts in the list \"texts\" (cf. Exercise 1.1) into lists of integers, each integer representing a token\n",
    "\n",
    "* **IMPORTANT** make sure to lowercase the tokens as the pre-trained embeddings we'll be using only include lowercased tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_int(tokens):\n",
    "    t_int = []\n",
    "    for t in tokens:\n",
    "        tl = t.lower()\n",
    "        token2int[tl]\n",
    "        t_int.append(token2int[tl])\n",
    "    return t_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knZtpGzZbKND"
   },
   "source": [
    "#### Exercise 4 - Create the reverse dictionaries (int2label, int2token) to map integer labels and integer tokens back to labels and tokens \n",
    "\n",
    "This is useful to be able to inspect results later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2label = { k : v for v, k in label2int.items()}\n",
    "int2token = { k : v for v, k in token2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dX_xNnPbKNJ"
   },
   "source": [
    "##### Pytorch import and key constants (PROVIDED)\n",
    "\n",
    "- `max_len` is the maximum sentence length\n",
    "- `batch_size` is the batch size\n",
    "- `embed_size` is the size of the pre-trained embeddings (word vectors). We use fasttext pre-trained embeddings of size 300.\n",
    "- `hidden_size` is the size of the RNN hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgHjYS72bKNP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "max_len = 16\n",
    "batch_size = 64\n",
    "embed_size = 300\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1  - Creating tensors\n",
    "\n",
    "To work with pytorch, all data must be converted to tensors. \n",
    "\n",
    "* X and Y are tensors of integers of size (number of sentences, max sentence length) initialised with 0 (this is the value of the padding symbol)\n",
    "* For each x and y, compute the length and cut down any instance that is over the max sentence length to that length\n",
    "* We populate the zeros tensors with the input data from exercise 1.1\n",
    "\n",
    "**Hint:** You did this in the previous lab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(text_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(label_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  6 - Create train and validation data\n",
    "\n",
    "* Split X into two parts, one called X_train which consists of the first 5000 items and the other called X_valid which includes the rest of the data\n",
    "* Do the same for Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:5000,:]\n",
    "X_test = X[5000:,:]\n",
    "y_train = y[:5000,:]\n",
    "y_test = y[5000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1duVtHubKNk"
   },
   "source": [
    "#### Exercise  7 - Use torch DataLoader to split training and validation data into batches\n",
    "\n",
    "**Hint:** This was provided in the previous lab sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# the TensorDataset is a ready to use class to represent your data as list of tensors. \n",
    "# Note that input_features and labels must match on the length of the first dimension\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "valid_set = TensorDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader shuffles and batches the data and load its in parallel using multiprocessing workers\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_9dJoanbKNp"
   },
   "source": [
    "## Using pre-trained Fasttext embeddings\n",
    "\n",
    "Instead of learning word embeddings using the network, we use pre-trained Fasttext embeddings. These are available [here](https://fasttext.cc/docs/en/english-vectors.html).\n",
    "\n",
    "However these cover several millions words and the files are large. Instead we'll use a smaller version which is restricted to the corpus vocabulary and is available on arche (wiki.en.filtered.vec). Each line in that file contains a token followed by the Fasttext embedding of that token(300 dimensions). \n",
    "E.g., auditorium -0.054196 -0.37375 ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_9dJoanbKNp"
   },
   "source": [
    "#### Exercise 8\n",
    "To use the pre-trained embeddings, we do the following:\n",
    "\n",
    "* first, we create a tensor of size (vocab_size, embedding_size) with embedding_size = 300 and values 0 (use torch.zeros method)\n",
    "\n",
    "* we store each line in wiki.en.filtered.vec  into a list \"tokens\" whose first element is the word and the second the pretrained fasttext emebdding\n",
    "\n",
    "* If the word is in our vocabulary we set the corresponding index (use your token2int dictionary) in our 0 tensor to the corresponding fasttext embedding. \n",
    "\n",
    "**N.B.** fasttext embeddings elements needs to be converted to float so you'll need to do something like\n",
    "\n",
    "torch.FloatTensor([float(x) for x in FSEmbedding])\n",
    "\n",
    "when setting the word index in the tensor to the fasttext embeddng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = open(\"wiki.en.filtered/wiki.en.filtered.vec\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(token2int)\n",
    "embeddings = torch.zeros(vocab_size, embed_size)\n",
    "tokens = []\n",
    "for line in vect: # Pour chaque liste\n",
    "        token = line.split(' ')[0] # On lit le token et son embedding\n",
    "        embed = line.split(' ')[1:]\n",
    "        tokens.append((token, embed)) # On les ajoute à la liste\n",
    "        \n",
    "        if token in token2int.keys(): # Si le token est dans le vocabulaire\n",
    "            embeddings[token2int[token]] = torch.FloatTensor([float(x) for x in embed]) # On le met dans le tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, train and evaluate your neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise  9 - Define your neural network (TODO: Provide missing values indicated by ??)\n",
    "\n",
    "As in the preceding Exercise sheet on neural classification, we define our RNN network as a subclass of pytorch RNN module. \n",
    "\n",
    "Our RNN consist of three layers:\n",
    "* the embedding layer: wich maps each token in the input to its fasttext embedding\n",
    "* A GRU layer: the recurrent layers\n",
    "* A decision layer which maps each input token to a label\n",
    "\n",
    "##### Padding\n",
    "If the input sentence is shorter than the maximum length, the remaining positions are filled with 0, the integer associated with the padding symbol. To exclude padding symbols  from the learning process (they are uninformative), include the padding_idx=vocab['<eos>'] option in the definition of the embedding layer and the \n",
    "\"bias=False\" option in the definition of the GRU layer. This forces the GRU hidden state to be null for all padding symbols. \n",
    "    \n",
    "##### Pre-trained Embeddings\n",
    "To ensure that the pretrained word embeddings are used:\n",
    "* set the `weight` attribute of the embedding layer to the pretrained embeddings\n",
    "* Use `requires_grad=False` to freeze the embedding layer so that the fasttext embeddings are not modified during learning.   \n",
    "If you do not use this option the embeddings are fine tuned during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "bbrhekbVbKN4",
    "outputId": "5fcdb589-e8f2-4a53-e113-541f9186a5cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embed): Embedding(4596, 300, padding_idx=0)\n",
       "  (rnn): GRU(300, 128, bias=False, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (decision): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size, padding_idx=token2int['<eos>'])\n",
    "        self.embed.weight = nn.Parameter(embeddings, requires_grad=False)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, bias=False, num_layers=1, \n",
    "                          bidirectional=False, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.decision = nn.Linear(hidden_size * 1 * 1, len(label2int))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x)\n",
    "        output, hidden = self.rnn(embed)\n",
    "        return self.decision(self.dropout(output))\n",
    "\n",
    "rnn_model = RNN()\n",
    "rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYepFTvcbKOF"
   },
   "source": [
    "#### Define a function to evaluate the performance of the model (PROVIDED)\n",
    "\n",
    "* the CrossEntropyLoss takes as input 2D matrices of shape (batch_size * sequence_length, num_labels)\n",
    "* Scores shape is adjusted accordingly\n",
    "* References are reshaped to (batch_size * sequence_length).\n",
    "* the max used to compute predictions applies to the last dimension of the y_scores tensors\n",
    "* To ignore padding symbols when computing the score, we create a matrix \"mask\" which contains 1 for all non nul elements of the Y matrix and O otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bc_mfttznImx",
    "outputId": "67ea45dd-650c-4ee7-a19a-4adcf6cd1988"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02202503124396958, 0.34460887949260044)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perf(model, loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    total_loss = correct = num_loss = num_perf = 0\n",
    "    for x, y in loader:\n",
    "      with torch.no_grad():\n",
    "        y_scores = model(x)\n",
    "        loss = criterion(y_scores.view(y.size(0) * y.size(1), -1), y.view(y.size(0) * y.size(1)))\n",
    "        y_pred = torch.max(y_scores, 2)[1]\n",
    "        mask = (y != 0)\n",
    "        correct += torch.sum((y_pred.data == y) * mask)\n",
    "        total_loss += loss.item()\n",
    "        num_loss += len(y)\n",
    "        num_perf += torch.sum(mask).item()\n",
    "    return total_loss / num_loss, correct.item() / num_perf\n",
    "\n",
    "perf(rnn_model, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbPWKZO2bKOJ"
   },
   "source": [
    "#### Exercise 10 - Define the training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply your model to a sentence\n",
    "\n",
    "Accuracy scores might be deceiving. We also need to look at the predictions on some example sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        for x_data, y_data in train_loader:\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_scores = model(x_data)\n",
    "            loss = criterion(y_scores.transpose(1, 2), y_data) # Modifications faites ici\n",
    "            num_samples += len(y_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        valid_loss, valid_acc = perf(model, valid_loader)\n",
    "        print(f'Epoch {epoch + 1}/{epochs} | Train loss: {total_loss/num_samples:.4f} | Valid loss: {valid_loss:.4f} | Acc: {valid_acc:.4%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train loss: 0.0080 | Valid loss: 0.0023 | Acc: 93.2699%\n",
      "Epoch 2/15 | Train loss: 0.0015 | Valid loss: 0.0014 | Acc: 96.0712%\n",
      "Epoch 3/15 | Train loss: 0.0010 | Valid loss: 0.0013 | Acc: 96.5469%\n",
      "Epoch 4/15 | Train loss: 0.0008 | Valid loss: 0.0011 | Acc: 97.0402%\n",
      "Epoch 5/15 | Train loss: 0.0008 | Valid loss: 0.0011 | Acc: 97.1635%\n",
      "Epoch 6/15 | Train loss: 0.0007 | Valid loss: 0.0011 | Acc: 97.1459%\n",
      "Epoch 7/15 | Train loss: 0.0006 | Valid loss: 0.0010 | Acc: 97.4278%\n",
      "Epoch 8/15 | Train loss: 0.0006 | Valid loss: 0.0010 | Acc: 97.3397%\n",
      "Epoch 9/15 | Train loss: 0.0005 | Valid loss: 0.0010 | Acc: 97.4278%\n",
      "Epoch 10/15 | Train loss: 0.0005 | Valid loss: 0.0010 | Acc: 97.6039%\n",
      "Epoch 11/15 | Train loss: 0.0004 | Valid loss: 0.0010 | Acc: 97.5687%\n",
      "Epoch 12/15 | Train loss: 0.0004 | Valid loss: 0.0010 | Acc: 97.6568%\n",
      "Epoch 13/15 | Train loss: 0.0004 | Valid loss: 0.0010 | Acc: 97.6568%\n",
      "Epoch 14/15 | Train loss: 0.0004 | Valid loss: 0.0010 | Acc: 97.6216%\n",
      "Epoch 15/15 | Train loss: 0.0003 | Valid loss: 0.0010 | Acc: 97.5687%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "fit(rnn_model, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 11 Apply your model to a sentence\n",
    "\n",
    "We define a `tag_sentence` function which:\n",
    "\n",
    "* takes a input the learned model and a sentence identifier i\n",
    "* retrieves from the data tensor X_valid the tensor for the i-th sentence (call it \"sentence\")\n",
    "* retrieves from the data tensor Y_valid the tensor of labels for the i-th sentence \n",
    "* put the model into evaluation mode\n",
    "* execute the model on the sentence tensor (\"sentence\")\n",
    "* extract the top predictions (use argmax)\n",
    "* print out the list of predicted tags \n",
    "   - use t.item() to get a value out of a tensor\n",
    "   - use your dictionary int2label to print out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, X_test):\n",
    "     #int2label[3] = 'B'\n",
    "    #sentence = X_test[i]\n",
    "    sentence = X_test\n",
    "    #labels = y_test[i]\n",
    "    model.eval()\n",
    "    y_scores = model(sentence)\n",
    "    y_pred = y_scores.argmax(2) # On choisit la classe avec les scores les plus élevés\n",
    "    #print('TOKEN'.ljust(10), 'PRED'.ljust(5), 'TRUE')\n",
    "    #print('-'*20)\n",
    "    #for j, pred in enumerate(y_pred):\n",
    "        #print(\n",
    "              #int2token[sentence[j].item()].ljust(10),\n",
    "              #int2label[pred.item()].ljust(5),\n",
    "              #int2label[labels[j].item()]\n",
    "        #)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tag_sentence(rnn_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = [[int2label[pred] for pred in l] for l in x.tolist()]\n",
    "true_label =  [[int2label[pred] for pred in l]for l in y_test.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           _       0.91      0.93      0.92      1490\n",
      "        eos>       0.98      1.00      0.99       465\n",
      "\n",
      "   micro avg       0.92      0.95      0.94      1955\n",
      "   macro avg       0.94      0.96      0.95      1955\n",
      "weighted avg       0.92      0.95      0.94      1955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "print(classification_report(true_label, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y = [int2label[pred] for pred in x.flatten().tolist()]\n",
    "true_y = [int2label[pred] for pred in y_test.flatten().tolist()]\n",
    "plot_confusion_matrix(true_y, pred_y, ['B','I','O','<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "05_tagging-crf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
