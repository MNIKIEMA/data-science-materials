{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()  # tokenization and feature extraction\n",
    "vect.fit(x_train)\n",
    "X_train = vect.transform(x_train)\n",
    "X_test =vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training, testing and evaluating a classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "# Create an object of the class *Perceptron*\n",
    "clf = Perceptron()\n",
    "# Learn the model by applying the function *fit()*\n",
    "clf.fit( X_train, y_train )\n",
    "# Predict the labels of the test instances\n",
    "y_pred = clf.predict( X_test )\n",
    "# Print the gold and predicted labels\n",
    "print( \"y true:\", y_test )\n",
    "print( \"y pred:\", y_pred )\n",
    "# Print the accuracy\n",
    "print( \"Acc:\", accuracy_score(y_test, y_pred ) )\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred ))\n",
    "# Print the confusion matrix\n",
    "print( confusion_matrix(y_test, y_pred ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examining the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vocabulary into a variable\n",
    "vocab = my_vectorizer.vocabulary_\n",
    "print( \"Vocabulary size:\", len(vocab) )\n",
    "\n",
    "\n",
    "ix_to_tokens = { v:k for k,v in vocab.items() }\n",
    "\n",
    "# Save the weights in a dict key = index, value = weight\n",
    "features_weights = {i:w for (i,w) in enumerate( clf.coef_[0] ) }\n",
    "\n",
    "# Sort and print the list of weights\n",
    "sorted_weights = sort_dict(features_weights)\n",
    "print( sorted_weights )\n",
    "\n",
    "# Reverse dictionnaries for labels and vocabulary\n",
    "\n",
    "# Reverse dictionnaries for labels and vocabulary\n",
    "# tag_to_idx = {class_name:class_idx,} e.g. {drama:1,comedy:0}\n",
    "ix_to_tag = { v:k for k,v in tag_to_ix.items() }\n",
    "\n",
    "# Look at the best features for each class\n",
    "print( '\\nBest features for identifying class 1, ie', ix_to_tag[1])\n",
    "print( '\\n'.join( [':'.join( (ix_to_tokens[i],str(w)) )for (w,i) in reversed( sorted_weights[-6:] )] ) )\n",
    "\n",
    "print( '\\nBest features for identifying class 0, ie', ix_to_tag[0])\n",
    "print( '\\n'.join( [':'.join( (ix_to_tokens[i],str(w)) ) for (w,i) in sorted_weights[:6]] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**\n",
    "\n",
    "The Chi-square test is used in statistics to test the independence of two events. In feature selection, we use it to test whether the occurrence of a specific term and the occurrence of a specific class are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "# N features with highest chi-squared statistics are selected\n",
    "chi2_features = SelectKBest(chi2, k = can be any number)\n",
    "X = chi2_features.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectKBest(chi2, k=5000)  # feature selection\n",
    "sel.fit(X_train,y_train)\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SKLearn pipeline object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2, k=5000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])\n",
    "\n",
    "classifier = pipeline.fit(x_train,y_train)\n",
    "predictions = classifier.predict(x_test)\n",
    "correct = 0\n",
    "for prediction,true_label in zip(predictions, y_test):\n",
    "    if prediction==true_label:\n",
    "        correct += 1\n",
    "print(correct/len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
