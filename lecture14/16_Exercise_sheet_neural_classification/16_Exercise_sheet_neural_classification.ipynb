{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7N-x97sa7h4"
   },
   "source": [
    "# Exercise Lecture 14: Neural Classification\n",
    "\n",
    "\n",
    "In this set of exercises, we will use a Recurrent Neural Network to classify BBC news articles into 5 topics. The dataset consists of 2225 documents and 5 categories: business, entertainment, politics, sport, and technology. \n",
    "\n",
    "\n",
    "The exercises cover the following points:\n",
    "\n",
    "* Converting the text in the corpus to vectors of integers (each integer represents a word in the corpus vocabulary)\n",
    "* Computing some descriptive statistics to identify a sentence length cutoff (sentences with longer lengths will not be considered for training)\n",
    "* Specifying, training and testing a recurrent neural network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing (PROVIDED)\n",
    "\n",
    "We first prepocessed the data to extract X (the input) and Y (the input labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_report</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tate &amp; Lyle boss bags top award\\n\\nTate &amp; Lyle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo 2 sells five million copies\\n\\nMicrosoft ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSPs hear renewed climate warning\\n\\nClimate c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pavey focuses on indoor success\\n\\nJo Pavey wi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tories reject rethink on axed MP\\n\\nSacked MP ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         news_report  labels\n",
       "0  Tate & Lyle boss bags top award\\n\\nTate & Lyle...       0\n",
       "1  Halo 2 sells five million copies\\n\\nMicrosoft ...       4\n",
       "2  MSPs hear renewed climate warning\\n\\nClimate c...       2\n",
       "3  Pavey focuses on indoor success\\n\\nJo Pavey wi...       3\n",
       "4  Tories reject rethink on axed MP\\n\\nSacked MP ...       2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "# for reproducibility\n",
    "random_state = 0 \n",
    "\n",
    "DATA_DIR = \"bbc\"\n",
    "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\", random_state=random_state)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'news_report': data['data'], 'labels': data['target']})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xchG9cxna7jE"
   },
   "source": [
    "Extracting X (texts) and Y (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\experiments\\cours nlp\\data science\\lecture14\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjVnCCXNa7jJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sport betting rules in spotlight\n",
      "\n",
      "a group of mps and peers has called for a tightening of regulations controlling betting on sport.\n",
      "\n",
      "the parliamentary group on betting and gaming held a substantial inquiry into betting last year. it followed fears that a massive increase in betting on sport, such as that done using the internet and mobile phones, has led to more cheating. the all-party group recommended 15 ways to protect punters and improve the integrity of sports betting. they include a proposal for raising the maximum jail sentence for gambling cheats above the current two years. lord condon, head of the international cricket council's anti-corruption unit, who originally made the call for longer prison sentences, said the two-year penalty was \"derisory\". \"you could get a bigger sentence for failing to pay your hotel bill criminally than you could for corruption in major sports. \"symbolically, a higher penalty, perhaps as the bill passes through the two houses, might be appropriate.\"\n",
      "\n",
      "the report recommended the governing bodies of sports have a say in the type of bets offered to punters, and for bookmakers to set up \"audit trails\" - something the new betting exchanges already do - to allow suspicious betting patterns to be traced.\n",
      "\n",
      "lord faulkner of worcester, who chaired the inquiry, said: \"whilst we accept that the greater part of sports betting is neither corrupt nor unfair to punters, the evidence convinces us that the growth of betting exchanges - because of the facility they provide to bet against a result - has increased the potential for corruption. \"it is important that the government works with sporting administrators to review the difficulties faced by governing bodies in convicting the guilty and penalising them appropriately.\" the panel's aim was to try to define what constitutes cheating, assess how much might be going on and suggest what the government might do to put it right. as well as the growth of internet and mobile phone betting, there has been the creation of betting exchanges which allow punters to fix odds between themselves. betting exchanges allow punters to back (to win) but also lay (to lose) a horse. this means they can control their odds at winning by placing their money both ways.\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "texts = df[\"news_report\"].str.lower()\n",
    "labels = df[\"labels\"]\n",
    "\n",
    "print(texts[12])\n",
    "print(labels[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the texts in the corpus to vectors of integers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYbQI1mka7kl"
   },
   "source": [
    "#### Exercise 1 -  Convert the corpus to a list of lists of integers\n",
    "\n",
    "* Define a dictionary tokens2int which maps each distinct token in the corpus to a distinct integer \n",
    "( the size of this dictionary is the size of the corpus vocabulary i.e., the number of distinct tokens in the corpus, cf. Python CS)\n",
    "* Use this dictionary to map each news report to a vector.\n",
    "\n",
    "\n",
    "**Example**\n",
    "* Input Texts: [\"The woman put the book on the table\",\"The woman reads\"]\n",
    "* Created vocabulary: {the, woman, put, book, on, table, reads}\n",
    "* Output Texts: [ [1,2,3,1,4,5,1,6], [1,2,7]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "all_vocab = []\n",
    "token2int = defaultdict(lambda: len(token2int)) #can we use enumerate to do that? \n",
    "token2int['<eos>'] = 0\n",
    "for text in texts:\n",
    "    tokens = word_tokenize(text)\n",
    "    token_ids = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        token_ids.append(token2int[token.lower()])\n",
    "        \n",
    "    all_vocab.append(token_ids)\n",
    "\n",
    "# Compr√©hension de liste\n",
    "token2int = defaultdict(lambda: len(token2int)) \n",
    "all_vocab = [[token2int[token.lower()] for token in nltk.word_tokenize(text)] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_text = []\n",
    "for l in texts:\n",
    "    tmp_list = []\n",
    "    for i in l.split():\n",
    "        tmp_list.append(token2int[i])\n",
    "    int_text.append(tmp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHT_bKtua7lJ"
   },
   "source": [
    "#### Exercise 2 - Define the reverse int2token mapping and check the token2int and the int2token mappings on an example\n",
    "\n",
    "* Check that the words have been correctly converted to integer by applying the reverse integer to token mapping\n",
    "* Print out the vocabulary size\n",
    "* Print out the maximum text length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2token = {v: k for k, v in token2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4432\n"
     ]
    }
   ],
   "source": [
    "print(max([len(l) for l in int_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 - Compute some statistics to determine which sentences to keep\n",
    "\n",
    "The maximum sentence size is very large (4432 tokens). Presumably most reports are not that long. Use pandas describe() method and matplotlib to get a better idea of the data distribution in terms of report length.\n",
    "\n",
    "* Compute the list of report lengths (list of nb of tokens for each report in the BBC news corpus)\n",
    "* Compute the box plots for report lengths\n",
    "* Use pandas desribe() method to get the descripte statistics (min, max, means, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_token'] = df['news_report'].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.set_theme()\n",
    "sns.boxplot(x = \"labels\", y = \"nb_token\", data = df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2225.000000\n",
       "mean      384.040449\n",
       "std       238.174497\n",
       "min        89.000000\n",
       "25%       246.000000\n",
       "50%       332.000000\n",
       "75%       471.000000\n",
       "max      4432.000000\n",
       "Name: nb_token, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nb_token'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxs8QE1Ha7ld"
   },
   "source": [
    "# 2  Classifying with a Recurrent Neural Network\n",
    "\n",
    "We import some pytorch submodules\n",
    "\n",
    "* torch: functions to create tensors and operations on tensors \n",
    "* torch.nn: to specify neural networks\n",
    "* torch.nn.functional for when we want to define a custom layer for example with a convolution operation layer.\n",
    "* torch.optim: optimizers for training \n",
    "\n",
    "We also need to specify some constants which ensure that the code can run on CPU. The `max_len` constant is important as text whose size exceeds (in number of tokens) that limit will be discarded. We set it to 471. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch-cpu torchvision-cpu -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SU-ibO_-a7ll"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C9UoOQka7l7"
   },
   "source": [
    "#### Exercise 4 - Creating tensors\n",
    "\n",
    "To help speed up computation, all data must be converted to tensors. \n",
    "\n",
    "* Set the maximum size of text to the 3rd quartile (471)\n",
    "* Create a tensor of size  (number of texts, maximum size of a text) for X. Call this tensor X. Longer texts will be cut down to maximal size and shorter texts will be padded with `<eos>`. Use torch.zeros method and make sure to specify the components will be of type integer (long attribute in torch)\n",
    "* Populate this matrix with the integer version of the BBC news report (cf. Exercise 1). Use the torch.LongTensor method. When populating the matrix cut down sentence whose length is above the max length to max length\n",
    "* Create another tensor of size (numbers of text) and populate it with the list of labels. Call this tensor Y.\n",
    "* Print out the shape of X and Y . X should be of size (2225, 471) and Y of size (2225,) \n",
    "\n",
    "N.B. In practice, it is not necessary to have all the data in a single tensor. In fact, this is inefficient if the texts have varied length. The only constraint is that for a given batch, all sequences have the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 471\n",
    "pad_text = []\n",
    "for l in all_vocab:\n",
    "    if len(l)>= max_size:\n",
    "        pad_text.append(l[:max_size+1])\n",
    "    else:\n",
    "        pad_text.append(l[:len(l)+1] + (max_size - len(l))*[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eakhMa5Sa7mL"
   },
   "source": [
    "#### Exercise 5 - Create train and test data\n",
    "\n",
    "* Split X into two parts, one called X_train which consists of the first 1112 items and the other called X_valid which includes the rest of the data\n",
    "* Do the same for Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZkXMuF0a7mj"
   },
   "source": [
    "#### Create batches (PROVIDED)\n",
    "\n",
    "pytorch provides a batch generator which shuffles the data. We apply it to train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veYFlstja7mm"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# the TensorDataset is a ready to use class to represent your data as list of tensors. \n",
    "# Note that input_features and labels must match on the length of the first dimension\n",
    "train_set = TensorDataset(X_train, Y_train)\n",
    "valid_set = TensorDataset(X_valid, Y_valid)\n",
    "\n",
    "# DataLoader shuffles and batches the data and load its in parallel using multiprocessing workers\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cwh1VKE1a7n1"
   },
   "source": [
    "#### Exercise 6 - Define your neural network\n",
    "\n",
    "We define a network by specifying a subclass of the appropriate pytorch modules. For instance here, as we want to create an RNN we create a subclass of pytorch RNN module. The specification of the network falls into 2 parts. \n",
    "\n",
    "In the init part, the layers of the network are defined and  their type and shape are specified.  \n",
    "\n",
    "In the forward part, we connect the layers and specify input and output for each layer. \n",
    " \n",
    "* The hidden state returned by the GRU layer is of size (num_layers * num_directions, batch_size, hidden_size) \n",
    "* The input to the decision layer should be of size (batch_size, hidden_size).   \n",
    "\n",
    "Hence the first 2 dimensions of hidden must be transposed and the tensor redimensioned to (batch_size, hidden_size).\n",
    "\n",
    "* drop : (num_layers * num_directions, batch_size, hidden_size)\n",
    "* drop.transpose(0,1): (batch_size, num_layers * num_directions,  hidden_size)\n",
    "* x.size(0) = batch_size\n",
    "* drop.transpose(0,1).contiguous.view(x.size(0), -1): (batchsize, hiddensize)\n",
    "\n",
    "**TODO:** fill in the missing variables (marked by ???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VyV6gWoOa7n7"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "  \n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Here we define the network layers\n",
    "        \n",
    "        # An embedding layer projecting vectors of size vocab_size into embeddings of size embed_size\n",
    "        # Assigns to each word in the vocabulary an embedding of size embed_size\n",
    "        self.embed = nn.Embedding(???, embed_size)\n",
    "        \n",
    "        # A recurrent (GRU) layer to process each input token (represented by its embedding)\n",
    "        # The GRU network takes as input the embedding (of size embed_size) of the current word \n",
    "        # and the previous hidden state (of size hidden_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        # Drop out layer for regularisation\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Fully connected layer mapping \n",
    "        # the last layer maps a hidden state to a vector of size the number of classes\n",
    "        self.decision = nn.Linear(hidden_size, ???)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        # Here we say how the layers are connected \n",
    "       \n",
    "        #  for each token in the input, retrieve the corresponding embeddings \n",
    "        \n",
    "        # x = [batch size, input size]\n",
    "        embed = self.embed(x)\n",
    "        # embed = [batch size, sent len, emb dim]       \n",
    "       \n",
    "        # Run the RNN on the input embeddings\n",
    "        # output is the sequence of hidden states produced by the RNN\n",
    "        # hidden is the last hidden state produced\n",
    "        output, hidden = self.rnn(???)\n",
    "        \n",
    "        # output = [sent len, batch size, hidden size]\n",
    "        # hidden = [num_layers * num_directions, batch size, hidden_size ]\n",
    "        \n",
    "        # Apply dropout (for regularisation)\n",
    "        drop = self.dropout(hidden)\n",
    "        \n",
    "        # drop = [num_layers * num_directions, batch size, hidden_size]   \n",
    "        \n",
    "        # Apply the fully connected layer to the output of the dropout\n",
    "        # Expected input size: [batch_size, input_size]\n",
    "        # We transpose [num_layers * num_directions, batch size, hidden_size ]\n",
    "        # to: [batch size, num_layers * num_directions, hidden_size ]\n",
    "        # And apply view to create an input of the form [batch size, input_size ]\n",
    "        # (x.size(0) = batch size)\n",
    "        return self.decision(drop.transpose(0, 1).view(x.size(0), -1))\n",
    "    \n",
    "rnn_model = RNN()\n",
    "rnn_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3276ujaa7nF"
   },
   "source": [
    "#### Exercise 7  - Evaluating \n",
    "\n",
    "We define an evaluation fonction (called \"perf\") which computes the average loss on the test/validation dataset and the proportion of correct cases. \n",
    "\n",
    "* We use pytorch nn.CrossEntropyLoss() as loss function.\n",
    "* For each batch returned by the loader, we calculate the scores produced by the model for each class, the loss, the predictions and the loss.\n",
    "* To block dropout (which should only be used at training time), we use the eval() method. \n",
    "* \"with torch.no_grad()\" temporarily set all the requires_grad flag to false. In practice, this enforces that gradients are not computed (and therefore the weights of the model remain unchanged). \n",
    "\n",
    "**TODO:** Modify the function so that it outputs the proportion of correct predictions in addition to the loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WW8p4Pnga7nH"
   },
   "outputs": [],
   "source": [
    "def perf(model, loader):\n",
    "    # define the loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # No drop out\n",
    "    model.eval()\n",
    "    total_loss = correct = num = 0\n",
    "    for x, y in loader:\n",
    "    # No gradient computation, weights remain unchanged\n",
    "      with torch.no_grad():\n",
    "        # Compute the scores for the instances in the input batch\n",
    "        y_scores = model(x)\n",
    "        # Compute the loss\n",
    "        loss = criterion(y_scores, y)\n",
    "        # Compute the predictions\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        # Update the batch loss\n",
    "        total_loss += loss.item()\n",
    "        num += len(y)\n",
    "    return total_loss / num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8  - Training Loop\n",
    "\n",
    "Define a function fit(model, epochs) which you will use to train your model\n",
    "\n",
    "* use the CrossEntropyLoss and the Adam optimizer\n",
    "* iterates over the epochs and for each epoch:\n",
    "   - Set the module in training mode (use the train() method). Drop out will apply and gradients will be computed. \n",
    "   - Initialise the total loss to 0\n",
    "   - Iterate over each batches returned by train_loader    \n",
    "     For each batch:   \n",
    "        - set the gradients to null (optimizer.zero_grad())\n",
    "        - predicts the batch scores\n",
    "        - calculate the loss\n",
    "        - back propagate\n",
    "        - optimize (adjust the weights)\n",
    "        - update the total loss\n",
    "   - print out the average loss on the training data and on the validation data as well as the proportion of correct cases on the validation data (use the perf function defined in the preceding exercise).\n",
    "   \n",
    "**Hint:** Some of these steps are defined in the preceding exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nlDoZhxa7oo"
   },
   "source": [
    "#### Exercise 9 - Training\n",
    "\n",
    "Use the fit function you just defined to train your model. \n",
    "* The loss function on the train and validation set should decrease\n",
    "* The accuracy on the validation set should improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model\n",
    "\n",
    "Here below is a CNN model definition. Run it on the data and compare the speed and results with that of the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(len(vocab), embed_size)\n",
    "        self.conv = nn.Conv1d(embed_size, hidden_size, kernel_size=2)\n",
    "        self.dropout = nn.Dropout(.3)\n",
    "        self.decision = nn.Linear(hidden_size, len(set(labels)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x)\n",
    "        conv = F.relu(self.conv(embed.transpose(1,2)))\n",
    "        pool = F.max_pool1d(conv, conv.size(2))\n",
    "        drop = self.dropout(pool)\n",
    "        return self.decision(drop.view(x.size(0), -1))\n",
    "\n",
    "cnn_model = CNN()\n",
    "cnn_model.to(device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "04_text-classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
