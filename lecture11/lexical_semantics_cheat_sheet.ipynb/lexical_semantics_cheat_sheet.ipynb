{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a vector  with 10 dimensions , all of value 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vector = np.zeros(10)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a dictionary using defaultdict** \n",
    "\n",
    "This avoids having python throw a KeyError when you try to get an item with a key that is not currently in the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "defaultdict(<class 'int'>, {'the': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(int)\n",
    "print(d.items())\n",
    "\n",
    "d[\"the\"] += 1\n",
    "print(d.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary mapping each token in a corpus to a distinct integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'<eos>': 0,\n",
       "             'A': 1,\n",
       "             'group': 2,\n",
       "             'of': 3,\n",
       "             'MPs': 4,\n",
       "             'and': 5,\n",
       "             'peers': 6,\n",
       "             'has': 7,\n",
       "             'called': 8,\n",
       "             'for': 9,\n",
       "             'a': 10,\n",
       "             'tightening': 11,\n",
       "             'regulations': 12,\n",
       "             'controlling': 13,\n",
       "             'betting': 14,\n",
       "             'on': 15,\n",
       "             'sport.': 16,\n",
       "             'This': 17,\n",
       "             'is': 18,\n",
       "             'annoying.': 19})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "texts = [\"A group of MPs and peers has called for a tightening of regulations controlling betting on sport.\", \"This is annoying.\"]\n",
    "\n",
    "# Create an empty dictionary using collections.defaultdic method\n",
    "# Set the default value that will be assigned to each token to the current size of the vocabulary\n",
    "token2int = collections.defaultdict(lambda: len(token2int)) \n",
    "\n",
    "# Set the value of <eos> to 0\n",
    "token2int['<eos>'] = 0\n",
    "\n",
    "# Add each new word in \"texts\" to the dictionary\n",
    "# and map it to the integer corresponding to its first position in the text (= the size of\n",
    "# the vocabulary present in the dictionary at that time)\n",
    "for text in texts:\n",
    "    [token2int[token] for token in text.split()]\n",
    "    \n",
    "token2int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying SVD decomposition to a matrix**\n",
    "\n",
    "[svd method](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-35b41c143bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# matrix must be a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# full_matrices = False ensures that reduced SVD is used (not full SVD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# matrix must be a matrix\n",
    "# full_matrices = False ensures that reduced SVD is used (not full SVD)\n",
    "U, s, V = np.linalg.svd(matrix, full_matrices = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a dataframe whose column and row headers are the same and the cell values are 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "a  0  0\n",
       "b  0  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vocab = [\"a\",\"b\"]\n",
    "print(vocab)\n",
    "vocab_len = len(vocab)\n",
    "df = pd.DataFrame(data=np.zeros((vocab_len, vocab_len)), dtype=np.int16,index=vocab,columns=vocab)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary mapping tokens to integer** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"a\",\"b\"]\n",
    "\n",
    "dict(zip(tokens,range(len(tokens))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a document/token matrix using sklean Countvectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 6)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 7)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 12)\t2\n",
      "  (3, 7)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 8)\t1\n",
      "  (4, 9)\t1\n",
      "  (5, 8)\t1\n",
      "  (5, 5)\t1\n",
      "  (5, 0)\t1\n",
      "[[0 0 0 0 0 0 1 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 1 0 0 0 1 2]\n",
      " [0 0 1 0 0 0 0 0 1 1 0 0 0]\n",
      " [1 0 0 0 0 1 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "docs = [\"Shakespeare wrote plays\",\"Shakespeare wrote poems\",\n",
    "        \"Hugo wrote novels\",\"Verne wrote novels\"\n",
    "        \"Rimbaud wrote poems\",\n",
    "        \"John read science\", \n",
    "        \"Peter read books\"]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a frequency vectorizer object\n",
    "# Help; using  the option \"stop_words = 'english'\" ensures that \n",
    "# stop_words are removed\n",
    "count_model = CountVectorizer(ngram_range=(1,1), stop_words = 'english') \n",
    "\n",
    "# Convert documents to document/token matrix by applying the vectoriser\n",
    "# the corpus (docs)\n",
    "X = count_model.fit_transform(docs)\n",
    "print(X)\n",
    "# Print out the document / token matrix\n",
    "# use the todense() attribute to create the matrix view\n",
    "print(X.todense()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shakespeare': 10, 'wrote': 12, 'plays': 6, 'poems': 7, 'hugo': 1, 'novels': 3, 'verne': 11, 'novelsrimbaud': 4, 'john': 2, 'read': 8, 'science': 9, 'peter': 5, 'books': 0}\n"
     ]
    }
   ],
   "source": [
    "print(count_model.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(count_model.vocabulary_['shakespeare'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
