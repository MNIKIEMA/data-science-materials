{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \"Lecture 11: Lexical Semantics\"\n",
    "\n",
    "\n",
    "In this set of exercises, we will convert words to vectors representing their distributional properties. \n",
    "\n",
    "We will start by building a word cooccurrences matrix from the Wikipedia corpus. \n",
    "\n",
    "We will then use Gensim and sklearn predefined methods to build an SVD word context matrix from the Wikipedia corpus used in the preceding two lectures. Finally we'll use cosine to compare the similarity between different pairs of words. \n",
    "\n",
    "The exercises cover the following points:\n",
    "\n",
    "* Converting a corpus to a list of integers where each integer represent a token (this is needed for efficient computation)\n",
    "* Computing a word frequency distribution \n",
    "* Creating word coocurrence matrices\n",
    "* Applying SVD decomposition\n",
    "* Finding neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a corpus from a set of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Store all files in 'data/wkp/' into a pandas dataframe with column Text where each row contains the content of one file\n",
    "\n",
    "* use os.scandir to list the files in the directory, read each file into a list of strings (one string per file)   \n",
    "_**Cheatsheet:**_ python_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airports of Serbia (Serbian Cyrillic: Аеродром...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An airport authority is an independent entity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An airport bus, or airport shuttle bus or airp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airport check-in is the process whereby passen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airport security refers to the techniques and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Votice (Czech pronunciation: [ˈvocɪtsɛ]; Germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>The surface area that interacts with the worki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>William Hogarth  (; 10 November 1697 – 26 Octo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Wolfgang Nordwig (born 27 August 1943) is a fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Židlochovice (Czech pronunciation: [ˈʒɪdloxovɪ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text\n",
       "0    Airports of Serbia (Serbian Cyrillic: Аеродром...\n",
       "1    An airport authority is an independent entity ...\n",
       "2    An airport bus, or airport shuttle bus or airp...\n",
       "3    Airport check-in is the process whereby passen...\n",
       "4    Airport security refers to the techniques and ...\n",
       "..                                                 ...\n",
       "155  Votice (Czech pronunciation: [ˈvocɪtsɛ]; Germa...\n",
       "156  The surface area that interacts with the worki...\n",
       "157  William Hogarth  (; 10 November 1697 – 26 Octo...\n",
       "158  Wolfgang Nordwig (born 27 August 1943) is a fo...\n",
       "159  Židlochovice (Czech pronunciation: [ˈʒɪdloxovɪ...\n",
       "\n",
       "[160 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "all_strings = []\n",
    "\n",
    "for filename in os.listdir('wkp'):\n",
    "    file_contents = open('wkp/' + filename).read()\n",
    "    all_strings.append(file_contents)\n",
    "\n",
    "df = pd.DataFrame(all_strings, columns=['Text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Clean the corpus\n",
    "\n",
    "* Store the content of the 'Text\" column into a string (cf. Pandas CS, \"Extracting all text from a colum\")\n",
    "* Tokenize the string into words (cf. NLTK CS)\n",
    "* Print out the first and the last 10 words of your list of tokens. Do you see tokens that may not be useful for learning word representations ?\n",
    "* Lower case all tokens and remove all tokens that contains characters that are not letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Airports', 'of', 'Serbia', '(', 'Serbian', 'Cyrillic', ':', 'Аеродроми', 'Србије', ')']\n",
      "['Italy', '==', 'References', '==', '==', 'External', 'links', '==', 'Official', 'website']\n",
      "\n",
      "['airports', 'of', 'serbia', 'serbian', 'cyrillic', 'аеродроми', 'србије', 'is', 'a', 'serbian']\n",
      "['with', 'gbely', 'slovakia', 'montevago', 'italy', 'references', 'external', 'links', 'official', 'website']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = ' '.join(df['Text'])\n",
    "tokenized_text = word_tokenize(text)\n",
    "\n",
    "print(tokenized_text[:10])\n",
    "print(tokenized_text[-10:])\n",
    "\n",
    "tokenized_text = [token.lower() for token in tokenized_text]\n",
    "tokenized_text = [token for token in tokenized_text if token.isalpha()]\n",
    "\n",
    "print()\n",
    "print(tokenized_text[:10])\n",
    "print(tokenized_text[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a frequency distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Create a frequency distribution from the list of tokens created in the previous exercise. Print out the 10 most and least frequent tokens.\n",
    "\n",
    "_**Cheatsheet:**_ lexical semantics and stats_and_visu \n",
    "* Create a frequency distribution by iterating over the list of token while incrementing each token frequency accordingly\n",
    "* Sort the tokens by decreasing frequency into a list\n",
    "* Print out the first and last 10 tokens of this list (which tokens are most and least frequent ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 11652), ('of', 5443), ('and', 4677), ('in', 4564), ('to', 3773), ('a', 3479), ('is', 1633), ('was', 1596), ('as', 1495), ('for', 1284)]\n",
      "[('linhart', 1), ('strakosch', 1), ('manó', 1), ('kogutowicz', 1), ('cartographer', 1), ('teschen', 1), ('admiral', 1), ('eugen', 1), ('gbely', 1), ('montevago', 1)]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "\n",
    "frequency_dist = nltk.FreqDist(tokenized_text)\n",
    "frequency_dist.plot(10)\n",
    "\n",
    "print(frequency_dist.most_common(10))\n",
    "print(frequency_dist.most_common()[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the corpus to a list of integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Convert the list of tokens created in Exercise 2 (corpus cleaning) into a list of integers\n",
    "\n",
    "* Create a dictionary mapping each token to a distinct integer (Cf. Lexical Semantics CS)\n",
    "* Use this dictionary to convert each token from your cleaned corpus (Exercise 2) into an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "token2int = defaultdict(lambda: len(token2int)) \n",
    "\n",
    "integer_text = [token2int[token] for token in tokenized_text]\n",
    "integer_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of co-occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** In the previous exercise, you created a list of integers where each integer is the identifier for the corresponding token in your cleaned up corpus. Iterate over that list and for each \"integer token\" *i*:\n",
    "\n",
    "* get the neihbours of *i* within a window of size 5 (only looking at the right side of *i*)\n",
    "* store these neihbours in a dictionary of coocurrences of the form {(i,j):f,} where *(i,j)* are neighbours and *f* is the frequency of the co-occurence \n",
    "* Sort co-occurences using integer order i.e., if the neighbour *n* is represented by an identifier smaller than *i*, store the co-occurence as *(n,i)*, otherwise as *(i,n)* .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrences = defaultdict(int)\n",
    "\n",
    "for i, token in enumerate(integer_text[:-5]):\n",
    "    for j in range(1, 6):\n",
    "        neighbour_token = integer_text[i + j]\n",
    "        cooccurrences[(min(token, neighbour_token), max(token, neighbour_token))] += 1\n",
    "cooccurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the SVD decomposition of the Co-occurence Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** Compute the  SVD decomposition of the word co-occurence matrix you just created\n",
    "\n",
    "* Create a matrix A of size (vocab_length, vocab_length)\n",
    "* Fill each cell *(i,j)* in this matrix with the frequency the co-occurrence between *i* and *j*\n",
    "* Use numpy [svd](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) method from the linalg module\n",
    "* full_matrices = False ensures that reduced SVD is applied (rather than full SVD)\n",
    "\n",
    "A = U * s * V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.,  37.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0., 627.,   9., ...,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   1.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.zeros((len(token2int), len(token2int)))\n",
    "for (i, j), value in cooccurrences.items():\n",
    "    matrix[i, j] = value\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17627"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, s, V = np.linalg.svd(matrix, full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7 (PROVIDED):** Define a function which returns the similarity between two words and apply to measure the similarity of airport and news, airport and international, john and peter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'U' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ff9ed2f1f1a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cosine(airport, news) ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'airport'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'news'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cosine(airport, international) ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'airport'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'international'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cosine(john, peter) ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'john'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'peter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'U' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def similarity(embedding, word1, word2):\n",
    "  if word1 in vocab and word2 in vocab:\n",
    "    v1 = embedding[token2int[word1]].reshape(1, -1)  \n",
    "    v2 = embedding[token2int[word2]].reshape(1, -1)\n",
    "    return cosine_similarity(v1, v2)[0][0]\n",
    "\n",
    "print('cosine(airport, news) =', similarity(U, 'airport', 'news'))\n",
    "print('cosine(airport, international) =', similarity(U, 'airport', 'international'))\n",
    "print('cosine(john, peter) =', similarity(U, 'john', 'peter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8 (PROVIDED):** Define a function which outputs the neighbours of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'U' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-89f0fa97efac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'airport'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'news'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'U' is not defined"
     ]
    }
   ],
   "source": [
    "reverse_vocab = {j: i for i, j in token2int.items()}\n",
    "\n",
    "def most_similar(embedding, word, n=10):\n",
    "  if word in vocab:\n",
    "    v = embedding[token2int[word]].reshape(1, -1)\n",
    "    scores = cosine_similarity(v, embedding).reshape(-1)\n",
    "    result = []\n",
    "\n",
    "    # argsort gives n-best scores\n",
    "    for i in reversed(scores.argsort()[-n:]):\n",
    "      result.append((reverse_vocab[i], scores[i]))\n",
    "    return result\n",
    "\n",
    "print(most_similar(U, 'airport'))\n",
    "print(most_similar(U, 'news'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating a word cooccurence matrix using vectorizers\n",
    "\n",
    "In the preceding section, we created the word co-occurence matrix programatically (we wrote the algorithm for deriving the matrix from the corpus). There is in fact a much quicker way to do this which can be summarised as follows:\n",
    "\n",
    "* Use sklearn vectorizer methods (CountVectorizer, TfidfVectorizer) to convert the corpus (a list of documents) to a _**document/token matrix**_\n",
    "* Use algebra to create the token/token matrix.  To create a _**token co-occurence matrix**_ , we simply multiply the transpose of the documents/tokens matrix by the documents/token matrix\n",
    "    * shape of X: (#doc, #tokens)   \n",
    "    * shape of X transpose: (#tokens, #doc)   \n",
    "    * shape of X transpose * X : (#tokens, #doc) * (#doc, #tokens) = (#tokens, #tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** Convert the Wikipedia files into a list of strings and preprocess each string\n",
    "\n",
    "* Convert the Text column of the dataframe created in Exercise 1 into a list of strings\n",
    "* Define a preprocessing function which takes a list of strings as input, tokenizes each string, lowercases the tokens, only keep tokens made of letters (use isalpha() method), convert the list of cleaned tokens back into a string (use \"join\") and stores the result into a lists of preprocessed strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = df['Text'].tolist()\n",
    "strings = [word_tokenize(string) for string in strings]\n",
    "strings = [[token for token in string if token.isalpha()] for string in strings]\n",
    "strings = [[token.lower() for token in string] for string in strings]\n",
    "strings = [' '.join(string) for string in strings]\n",
    "strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 10:** Creating a document / token matrix\n",
    "\n",
    "* Use sklearn [sklearn.feature_extraction.text.CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) method which transforms a list of documents (strings) into a a document/token matrix where each cell indicates the frequency of a token in a document\n",
    "* Use the stop_words option to remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 399)\t8\n",
      "  (0, 13795)\t8\n",
      "  (0, 13796)\t2\n",
      "  (0, 3784)\t1\n",
      "  (0, 17230)\t1\n",
      "  (0, 17246)\t1\n",
      "  (0, 3076)\t2\n",
      "  (0, 11145)\t1\n",
      "  (0, 10940)\t1\n",
      "  (0, 6969)\t1\n",
      "  (0, 10841)\t1\n",
      "  (0, 10608)\t1\n",
      "  (0, 3309)\t1\n",
      "  (0, 6642)\t1\n",
      "  (0, 398)\t9\n",
      "  (0, 6058)\t1\n",
      "  (0, 8134)\t1\n",
      "  (0, 6579)\t1\n",
      "  (0, 9379)\t3\n",
      "  (0, 15314)\t1\n",
      "  (0, 9443)\t1\n",
      "  (0, 4229)\t1\n",
      "  (0, 9390)\t1\n",
      "  (0, 7742)\t1\n",
      "  (0, 1564)\t2\n",
      "  :\t:\n",
      "  (159, 9487)\t1\n",
      "  (159, 11463)\t1\n",
      "  (159, 17173)\t1\n",
      "  (159, 4285)\t1\n",
      "  (159, 6766)\t1\n",
      "  (159, 10121)\t1\n",
      "  (159, 3136)\t1\n",
      "  (159, 1208)\t1\n",
      "  (159, 7358)\t1\n",
      "  (159, 1647)\t1\n",
      "  (159, 10177)\t1\n",
      "  (159, 11462)\t1\n",
      "  (159, 10614)\t4\n",
      "  (159, 16793)\t1\n",
      "  (159, 9042)\t1\n",
      "  (159, 14779)\t1\n",
      "  (159, 9500)\t1\n",
      "  (159, 8584)\t1\n",
      "  (159, 2368)\t1\n",
      "  (159, 898)\t3\n",
      "  (159, 15471)\t1\n",
      "  (159, 224)\t1\n",
      "  (159, 5341)\t1\n",
      "  (159, 6364)\t1\n",
      "  (159, 10148)\t1\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_model = CountVectorizer(ngram_range=(1,1), stop_words='english') \n",
    "X = count_model.fit_transform(strings)\n",
    "\n",
    "print(X)\n",
    "print(X.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 11:** Print out the vocabulary i.e., the tokens contained in the document/token matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_model.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12:** Create the co-occurence matrix.\n",
    "\n",
    "To create a token co-occurence matrix, we simply multiply the transpose of the documents/tokens matrix by the documents/token matrix\n",
    "\n",
    "* shape of X: (#doc, #tokens)\n",
    "* shape of X transpose: (#tokens, #doc)\n",
    "* shape of X transpose * X : (#tokens, #doc) * (#doc, #tokens) = (#tokens, #tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17304x17304 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 28960976 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = X.transpose() * X\n",
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13:** Use the function given in Exercise 7 to measure the similarity of airport and news, airport and international, john and peter\n",
    "\n",
    "* You'll need to modify that part of the function which retrieves the identifier of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine(airport, news) = 0.3706508364612424\n",
      "cosine(airport, international) = 0.023942692718696652\n",
      "cosine(john, peter) = 0.030502480855017212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def similarity(embedding, word1, word2):\n",
    "    v1 = embedding[token2int[word1]].reshape(1, -1)  \n",
    "    v2 = embedding[token2int[word2]].reshape(1, -1)\n",
    "    return cosine_similarity(v1, v2)[0][0]\n",
    "\n",
    "print('cosine(airport, news) =', similarity(U, 'airport', 'news'))\n",
    "print('cosine(airport, international) =', similarity(U, 'airport', 'international'))\n",
    "print('cosine(john, peter) =', similarity(U, 'john', 'peter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
