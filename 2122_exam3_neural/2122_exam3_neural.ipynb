{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam session #3\n",
    "## Neural Classification\n",
    "\n",
    "#### Please enter your firstname and lastname below.\n",
    "\n",
    "- Firstname: **Mahamadi**\n",
    "- Lastname: **NIKIEMA**\n",
    "\n",
    "In this assignment, we develop a model for sentiment analysis, a task which consists in predicting a sentiment label of a text. We use a small corpus of **tweets** which have been annotated with a **target** (apple, microsoft, google...) and a **sentiment label**.\n",
    "\n",
    "**Data file : sanders-twitter-sentiment.csv**\n",
    "\n",
    "The assignement includes 4 main steps.\n",
    "\n",
    "1. Loading labels, targets and tweets into a Pandas dataframe (4 points)\n",
    "2. Converting tweets and labels to integers (14 points)\n",
    "3. Creating Training and Validation Data (6 points)\n",
    "4. Inspecting results of RNN classifier (14 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading tweets and labels into a Pandas Dataframe (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   Exercise 1.1 (2 points)\n",
    "\n",
    "* Load the sanders-twitter-sentiment.csv file into a pandas dataframe\n",
    "* Create a new dataframe called `data` which contains three columns with headers and content  `label`, `target` and `tweet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sanders-twitter-sentiment.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1044</td>\n",
       "      <td>125667332931596290</td>\n",
       "      <td>2011-10-16 20:20:01</td>\n",
       "      <td>&amp;quot;3 principal global players will be activ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>126384526925639681</td>\n",
       "      <td>2011-10-18 19:49:53</td>\n",
       "      <td>If you've been struggling to get hold of me, I...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278</td>\n",
       "      <td>126281019476291585</td>\n",
       "      <td>2011-10-18 12:58:35</td>\n",
       "      <td>@azee1v1 @apple @umber Proper consolidation, p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5743</td>\n",
       "      <td>126862268725080065</td>\n",
       "      <td>2011-10-20 03:28:16</td>\n",
       "      <td>me acabo de dar cuenta q tengo mas seguidores ...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510</td>\n",
       "      <td>126054725727698944</td>\n",
       "      <td>2011-10-17 21:59:23</td>\n",
       "      <td>With Siri, Apple Could Eventually Build A Real...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_1                id_2                 date  \\\n",
       "0  1044  125667332931596290  2011-10-16 20:20:01   \n",
       "1    71  126384526925639681  2011-10-18 19:49:53   \n",
       "2   278  126281019476291585  2011-10-18 12:58:35   \n",
       "3  5743  126862268725080065  2011-10-20 03:28:16   \n",
       "4   510  126054725727698944  2011-10-17 21:59:23   \n",
       "\n",
       "                                               tweet       label   target  \n",
       "0  &quot;3 principal global players will be activ...     neutral    apple  \n",
       "1  If you've been struggling to get hold of me, I...     neutral    apple  \n",
       "2  @azee1v1 @apple @umber Proper consolidation, p...    negative    apple  \n",
       "3  me acabo de dar cuenta q tengo mas seguidores ...  irrelevant  twitter  \n",
       "4  With Siri, Apple Could Eventually Build A Real...     neutral    apple  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[[\"label\", \"tweet\", \"target\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2 - Print out some examples (2 points)\n",
    "\n",
    "* Print out the number of rows and columns\n",
    "* Print out the 1st and secondcolumn of the 1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows is 5513 rows \n",
      " The number of column is 3 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of rows is {data.shape[0]} rows \\n The number of column is {data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                                               neutral\n",
       "tweet     &quot;3 principal global players will be activ...\n",
       "target                                                apple\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       2503\n",
       "irrelevant    1786\n",
       "negative       654\n",
       "positive       570\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Converting tweets and labels to integers (14 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1 -  Store tweets and labels into list (2 points)\n",
    "\n",
    "*  Write a function which returns two lists `texts` and `labels` where\n",
    "   - texts is the list of tweets  with each tweet prefixed with its target surrounded by < and >   \n",
    "   E.g., `<apple>` Wow I am loving this new @apple update for my touch. #coolness Well done\n",
    "   - labels is the corresponding list of labels\n",
    "\n",
    "* Print out \n",
    "   - the number of tweets\n",
    "   - an example tweet and its corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets(df):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for txt, target, label in zip(df[\"tweet\"],df[\"target\"], df[\"label\"]):\n",
    "        texts.append([f\"<{target}> \" + txt])\n",
    "        labels.append([label])\n",
    "    return texts, labels                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = tweets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2  - Create the vocabulary (2 points)\n",
    "   \n",
    "* Extract the corpus vocabulary from `texts`, the list of tweets created in Exercise 2.1\n",
    "   The vocabulary is the set of distinct tokens occurring in the tweets\n",
    "* Print out the size of the vocabulary (=the number of distinct tokens in the corpus of tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk  import word_tokenize\n",
    "tweet = data[\"tweet\"].str.lower()\n",
    "vocab = set(word_tokenize(tweet.str.cat(sep = ' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17134"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.3 - Convert tweets  to integers (2 points)\n",
    "   \n",
    "* Define a dictionary `token2int` which assigns 0 to the `<eos>` symbol and which maps each  token in the corpus to an  integer. Each token (including the  `<eos>` symbol) should be mapped to a different integer and none of the vocabulary token should be mapped to 0 (since 0 is the index of the `<eos>` symbol).\n",
    "* Define the reverse dictionary `int2token`\n",
    "\n",
    "Example\n",
    "\n",
    "Input Texts: [\"The woman put the book on the table\",\"The woman reads\"]   \n",
    "Created vocabulary: {the, woman, put, book, on, table, reads}    \n",
    "token2int: {the:1,woman:2,put:3,book:4,on:5,table:6,reads:7}   \n",
    "int2token: {1:the,2:woman,3:put,4:book,5:on,6:table,7:reads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "token2int = defaultdict(lambda: len(token2int))\n",
    "token2int['<eos>'] = 0\n",
    "for l in texts:\n",
    "    [token2int[token.lower()] for token in l[0].split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2token = { k : v for v, k in token2int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.4  - Converting labels to integers (2 points)\n",
    " \n",
    "* Define a dictionary `label2int` which maps each distinct label in labels to a distinct integer. \n",
    "* Define the reverse dictionary `int2label`\n",
    "* Print out the length of your label2int dictionary\n",
    "* Print out the set of labels used to annotate the sentiment of a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = defaultdict(lambda: len(label2int))\n",
    "label2int['<eos>'] = 0\n",
    "for label in ['neutral', 'irrelevant', 'negative', 'positive']:\n",
    "    label2int[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2label = { k : v for v, k in label2int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.5  - Sanity check (4 points)\n",
    "\n",
    "* Define a function `check_converting` which   \n",
    "   - converts a string to a list of tokens\n",
    "   - converts this list of tokens to the corresponding list of integers using `token2int` (cf Ex. 2.3)\n",
    "   - print this list of integers\n",
    "   - converts this list of integers back to a list tokens using `int2token` (cf Ex. 2.3)\n",
    "   - converts this list to a string (use `join`)\n",
    "   - prints out the resulting list of tokens\n",
    "* Apply this function to the 5th tweet in the list `texts` created in Ex. 2.1.\n",
    "\n",
    "**Hint** The input and output of this function should be identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_converting(text):\n",
    "    tokens = word_tokenize(text[0].lower())\n",
    "    tokens2int = [token2int[token] for token in tokens]\n",
    "    rev2tokens = [int2token[int_token] for int_token in tokens2int]\n",
    "    text = ' '.join(rev2tokens)\n",
    "    return rev2tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_converting(texts[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.6 - Converting the lists of tweets and labels to their indices (2)\n",
    "* Converts the list of tweets created in Exercise 2.1 to the corresponding list of lists of indices using `token2int` (created in Exercise 2.3)\n",
    "* Converts the list of labels created in Exercise 2.1 to the corresponding list of lists of indices using `label2int`  (created in Exercise 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ind = [[token2int[token.strip()] for token in s[0].split()] for s in texts]\n",
    "labels_ind = [label2int[lab[0].strip()] for lab in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. Creating Training and Validation Data (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "max_len = 16\n",
    "batch_size = 64\n",
    "embed_size = 128\n",
    "hidden_size = 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1 - Creating tensors (2 points)\n",
    "\n",
    "* Create a torch tensor of dimension `(nb of tweets, max_len)` whose values are 0; Call this tensor X\n",
    "* Populate this tensor with the integer representation of the tweets created in Ex.2.6\n",
    "* Create a tensor Y of dimension `(nb of tweets,)` and populate it with the integer representation of the corresponding sentiment label created in Ex.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_int = []\n",
    "for sent in texts_ind:\n",
    "    to_add = max_len - len(sent)\n",
    "    sent += [0] * to_add\n",
    "    text_int.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(5513, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:5000]\n",
    "X_valid = X[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2 - Divide X  into  X_train (the first 5000 tweets), X_valid (the remaining tweets) and similarly for Y  (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3 - Use pytorch TensorDataset and DataLoader to shuffle the data and the labels  (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Model (14 points)\n",
    "\n",
    "We use an RNN to classify the tweets. The code for training and testing is provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the loss\n",
    "def perf(model, loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    total_loss = correct = num = 0\n",
    "    for x, y in loader:\n",
    "      with torch.no_grad():\n",
    "        y_scores = model(x)\n",
    "        loss = criterion(y_scores, y)\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        correct += torch.sum(y_pred.data == y).item()\n",
    "        total_loss += loss.item()\n",
    "        num += len(y)\n",
    "    return total_loss / num, correct / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training loop\n",
    "def fit(model, epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_scores = model(x)\n",
    "            loss = criterion(y_scores, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            num += len(y)\n",
    "        print(epoch, total_loss / num, *perf(model, valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(len(token2int), embed_size, padding_idx=token2int['<eos>'])\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.decision = nn.Linear(hidden_size * 1 * 1, len(label2int))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x)\n",
    "        output, hidden = self.rnn(embed)\n",
    "        return self.decision(hidden.transpose(0, 1).contiguous().view(x.size(0), -1))\n",
    "\n",
    "rnn_model = RNN()\n",
    "rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.1  - Testing dimensions (4 points)\n",
    "\n",
    "* Call the model on the first 3 tweets . Explain the dimension of the output: what does it correspond to ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.2  - Train the model on 5 epochs  (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(rnn_model, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.3 - Print out the accuracy of the model on the training set and on the validation set  (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.4 - Plot the training and validation loss (2 points)\n",
    "\n",
    "- X is the number of epoch\n",
    "- Y is the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.5 - Plot the accuracy on the validation set (2 points)\n",
    "\n",
    "- X is the number of epochs\n",
    "- Y is the accuracy at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
